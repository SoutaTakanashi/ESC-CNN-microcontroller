@article{TensorFlowSpeechCommands,
title={Speech Commands: A public dataset for single-word speech recognition.},
author={Warden, Pete},
journal={Dataset available from http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz},
year={2017}
}
@article{CMSISNN,
  author    = {Liangzhen Lai and
               Naveen Suda and
               Vikas Chandra},
  title     = {{CMSIS-NN:} Efficient Neural Network Kernels for Arm Cortex-M CPUs},
  journal   = {CoRR},
  volume    = {abs/1801.06601},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.06601},
  archivePrefix = {arXiv},
  eprint    = {1801.06601},
  timestamp = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-06601},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{KeywordSpottingMFCCSettings,
author={M. Shahnawaz and E. Plebani and I. Guaneri and D. Pau and M. Marcon},
booktitle={2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
title={Studying the Effects of Feature Extraction Settings on the Accuracy and Memory Requirements of Neural Networks for Keyword Spotting},
year={2018},
volume={},
number={},
pages={1-6},
keywords={Feature extraction;Speech recognition;Hidden Markov models;Random access memory;Recurrent neural networks;Computer architecture},
doi={10.1109/ICCE-Berlin.2018.8576243},
ISSN={2166-6822},
month={Sep.},}
@article{Veniat2018StochasticAN,
  title={Stochastic Adaptive Neural Architecture Search for Keyword Spotting},
  author={Tom V'eniat and Olivier Schwander and Ludovic Denoyer},
  journal={CoRR},
  year={2018},
  volume={abs/1811.06753}
}
@article{Tang2018AnEA,
  title={An Experimental Analysis of the Power Consumption of Convolutional Neural Networks for Keyword Spotting},
  author={Raphael Tang and Weijie Wang and Zhucheng Tu and Jimmy Lin},
  journal={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2018},
  pages={5479-5483}
}
@Inproceedings{FastGRNN,
author = {Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
title = {FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network},
year = {2018},
month = {December},
url = {https://www.microsoft.com/en-us/research/publication/fastgrnn-a-fast-accurate-stable-and-tiny-kilobyte-sized-gated-recurrent-neural-network/},
}
@inproceedings{UrbanSound8k,
Address = {Orlando, FL, USA},
Author = {Salamon, J. and Jacoby, C. and Bello, J. P.},
Booktitle = {22nd ACM International Conference on Multimedia (ACM-MM'14)},
Month = {Nov.},
Pages = {1041--1044},
Title = {A Dataset and Taxonomy for Urban Sound Research},
Year = {2014},
}

@conference{Freesound,
	title = {Freesound Technical Demo},
	booktitle = {ACM International Conference on Multimedia (MM{\textquoteright}13)},
	year = {2013},
	month = {21/10/2013},
	pages = {411-412},
	publisher = {ACM},
	organization = {ACM},
	address = {Barcelona, Spain},
	abstract = {Freesound is an online collaborative sound database where people with diverse interests share recorded sound samples under Creative Commons licenses. It was started in 2005 and it is being maintained to support diverse research projects and as a service to the overall research and artistic community.
In this demo we want to introduce Freesound to the multimedia community and show its potential as a research resource. We begin by describing some general aspects of Freesound, its architecture and functionalities, and then explain potential usages that this framework has for research applications.},
	keywords = {audio clips, freesound, online databases, sound},
	isbn = {978-1-4503-2404-5},
	doi = {10.1145/2502081.2502245},
	author = {Frederic Font and Gerard Roma and Xavier Serra}
}

@article{MAIJALA2018258,
title = "Environmental noise monitoring using source classification in sensors",
journal = "Applied Acoustics",
volume = "129",
pages = "258 - 267",
year = "2018",
issn = "0003-682X",
doi = "https://doi.org/10.1016/j.apacoust.2017.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0003682X17307533",
author = "Panu Maijala and Zhao Shuyang and Toni Heittola and Tuomas Virtanen",
keywords = "Environmental noise monitoring, Acoustic pattern classification, Wireless sensor network, Cloud service",
}
@ARTICLE{Sigitia2016,
author={S. {Sigtia} and A. M. {Stark} and S. {Krstulović} and M. D. {Plumbley}},
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
title={Automatic Environmental Sound Recognition: Performance Versus Computational Cost},
year={2016},
volume={24},
number={11},
pages={2096-2107},
keywords={acoustic signal processing;Gaussian processes;mixture models;signal classification;speech recognition;support vector machines;automatic speech recognition;support vector machines;Gaussian mixture models;deep neural networks;sound classification performance;AESR algorithms;automatic environmental sound recognition algorithm;form factor;product pricing;embedded platforms;sound sensing;Internet of Things;performance cost;computational cost function;Computational efficiency;Speech;Speech recognition;Acoustics;Internet of things;IEEE transactions;Speech processing;Automatic environmental sound recognition;computational auditory scene analysis;deep learning;machine learning},
doi={10.1109/TASLP.2016.2592698},
ISSN={2329-9290},
month={Nov},
}

@misc{STEVAL-STLKT01V1,
title={STEVAL-STLKT01V1 product information},
author={STMicroelectronics},
url="https://www.st.com/en/evaluation-tools/steval-stlkt01v1.html",
}

@misc{STM32L476,
title={DS10198: STM32L476xx datasheet},
author={STMicroelectronics},
url="https://www.st.com/en/microcontrollers/stm32l476rg.html",
}

@misc{librosa,
  author       = {Brian McFee and
                  Matt McVicar and
                  Stefan Balke and
                  Vincent Lostanlen and
                  Carl Thomé and
                  Colin Raffel and
                  Dana Lee and
                  Kyungyun Lee and
                  Oriol Nieto and
                  Frank Zalkow and
                  Dan Ellis and
                  Eric Battenberg and
                  Ryuichi Yamamoto and
                  Josh Moore and
                  Ziyao Wei and
                  Rachel Bittner and
                  Keunwoo Choi and
                  nullmightybofo and
                  Pius Friesch and
                  Fabian-Robert Stöter and
                  Thassilo and
                  Matt Vollrath and
                  Siddhartha Kumar Golu and
                  nehz and
                  Simon Waloschek and
                  Seth and
                  Rimvydas Naktinis and
                  Douglas Repetto and
                  Curtis "Fjord" Hawthorne and
                  CJ Carr},
  title        = {librosa/librosa: 0.6.3},
  month        = feb,
  year         = 2019,
  doi          = {10.5281/zenodo.2564164},
  url          = {https://doi.org/10.5281/zenodo.2564164}
}

@misc{FP-AI-SENSING1,
title={FP-AI-SENSING1 function pack},
author={STMicroelectronics},
url="https://www.st.com/en/embedded-software/fp-ai-sensing1.html",
}

@InProceedings{ST-FD-SOI,
author="Desoli, Giuseppe
and Tomaselli, Valeria
and Plebani, Emanuele
and Urlini, Giulio
and Pau, Danilo
and D'Alto, Viviana
and Majo, Tommaso
and De Ambroggi, Fabio
and Boesch, Thomas
and Singh, Surinder-pal
and Guidetti, Elio
and Chawla, Nitin",
editor="Blanc-Talon, Jacques
and Distante, Cosimo
and Philips, Wilfried
and Popescu, Dan
and Scheunders, Paul",
title="The Orlando Project: A 28 nm FD-SOI Low Memory Embedded Neural Network ASIC",
booktitle="Advanced Concepts for Intelligent Vision Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="217--227",
abstract="The recent success of neural networks in various computer vision tasks open the possibility to add visual intelligence to mobile and wearable devices; however, the stringent power requirements are unsuitable for networks run on embedded CPUs or GPUs. To address such challenges, STMicroelectronics developed the Orlando Project, a new and low power architecture for convolutional neural network acceleration suited for wearable devices. An important contribution to the energy usage is the storage and access to the neural network parameters. In this paper, we show that with adequate model compression schemes based on weight quantization and pruning, a whole AlexNet network can fit in the local memory of an embedded processor, thus avoiding additional system complexity and energy usage, with no or low impact on the accuracy of the network. Moreover, the compression methods work well across different tasks, e.g. image classification and object detection.",
isbn="978-3-319-48680-2"
}

@misc{emlearn,
  author       = {Jon Nordby},
  title        = {{emlearn: Machine Learning inference engine for 
                   Microcontrollers and Embedded Devices}},
  month        = mar,
  year         = 2019,
  doi          = {10.5281/zenodo.2589394},
  url          = {https://doi.org/10.5281/zenodo.2589394}
}
@online{EuNoiseDirective,
    author    = "",
    title     = "EU directive 2002/49/EC",
    url       = "http://ec.europa.eu/environment/noise/directive_en.htm",
}

@online{Sonyc,
    title     = "SONYC",
    url       = "http://wp.nyu.edu/sonyc",
    keywords  = "deployment",
}

@misc{Forurensningsloven,
    title="Forskrift om begrensning av forurensning, del 2. Støy",
    url="https://lovdata.no/dokument/SF/forskrift/2004-06-01-931/KAPITTEL_2#KAPITTEL_2",
    year={2004},
    keywords="legislation",
}

@Article{AudioCodingSensorGrid,
AUTHOR = {Gontier, Félix and Lagrange, Mathieu and Aumond, Pierre and Can, Arnaud and Lavandier, Catherine},
TITLE = {An Efficient Audio Coding Scheme for Quantitative and Qualitative Large Scale Acoustic Monitoring Using the Sensor Grid Approach},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2758},
URL = {http://www.mdpi.com/1424-8220/17/12/2758},
ISSN = {1424-8220},
DOI = {10.3390/s17122758},
}

@misc{IECSoundLevelMeters,
title="IEC 61672-1 Sound Level Meters, part 1: Specifications",
year={2013},
url="https://standards.globalspec.com/std/1634276/iec-61672-1",
}
@misc{IECPersonalSoundExposureMeters,
title="IEC 61252 Personal Sound Exposure Meters",
year={2017},
url="https://standards.globalspec.com/std/10153028/IEC%2061252",
}
@misc{IECOctaveBands,
title="IEC 61260-1:2014",
year={2014},
url="https://webstore.iec.ch/publication/5063",
}
