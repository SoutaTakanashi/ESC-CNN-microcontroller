@article{TensorFlowSpeechCommands,
title={Speech Commands: A public dataset for single-word speech recognition.},
author={Warden, Pete},
journal={Dataset available from http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz},
year={2017}
}
@article{CMSISNN,
  author    = {Liangzhen Lai and
               Naveen Suda and
               Vikas Chandra},
  title     = {{CMSIS-NN:} Efficient Neural Network Kernels for Arm Cortex-M CPUs},
  journal   = {CoRR},
  volume    = {abs/1801.06601},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.06601},
  archivePrefix = {arXiv},
  eprint    = {1801.06601},
  timestamp = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-06601},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@online{uTensor,
author={Neil Tan},
title={uTensor: AI Inference library based on mbed and TensorFlow},
}

@misc{Keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}

@online{LaunchingTensorflowLiteMicrocontrollers,
title={Launching TensorFlow Lite for Microcontrollers},
author={Pete Warden},
year={2019},
month={03},  
}
https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/


@INPROCEEDINGS{KeywordSpottingMFCCSettings,
author={M. Shahnawaz and E. Plebani and I. Guaneri and D. Pau and M. Marcon},
booktitle={2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
title={Studying the Effects of Feature Extraction Settings on the Accuracy and Memory Requirements of Neural Networks for Keyword Spotting},
year={2018},
volume={},
number={},
pages={1-6},
keywords={Feature extraction;Speech recognition;Hidden Markov models;Random access memory;Recurrent neural networks;Computer architecture},
doi={10.1109/ICCE-Berlin.2018.8576243},
ISSN={2166-6822},
month={Sep.},}
@article{Veniat2018StochasticAN,
  title={Stochastic Adaptive Neural Architecture Search for Keyword Spotting},
  author={Tom V'eniat and Olivier Schwander and Ludovic Denoyer},
  journal={CoRR},
  year={2018},
  volume={abs/1811.06753}
}
@article{Tang2018AnEA,
  title={An Experimental Analysis of the Power Consumption of Convolutional Neural Networks for Keyword Spotting},
  author={Raphael Tang and Weijie Wang and Zhucheng Tu and Jimmy Lin},
  journal={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2018},
  pages={5479-5483}
}
@Inproceedings{FastGRNN,
author = {Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
title = {FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network},
year = {2018},
month = {December},
url = {https://www.microsoft.com/en-us/research/publication/fastgrnn-a-fast-accurate-stable-and-tiny-kilobyte-sized-gated-recurrent-neural-network/},
}
@inproceedings{UrbanSound8k,
Address = {Orlando, FL, USA},
Author = {Salamon, J. and Jacoby, C. and Bello, J. P.},
Booktitle = {22nd ACM International Conference on Multimedia (ACM-MM'14)},
Month = {Nov.},
Pages = {1041--1044},
Title = {A Dataset and Taxonomy for Urban Sound Research},
Year = {2014},
}

@conference{Freesound,
	title = {Freesound Technical Demo},
	booktitle = {ACM International Conference on Multimedia (MM{\textquoteright}13)},
	year = {2013},
	month = {21/10/2013},
	pages = {411-412},
	publisher = {ACM},
	organization = {ACM},
	address = {Barcelona, Spain},
	abstract = {Freesound is an online collaborative sound database where people with diverse interests share recorded sound samples under Creative Commons licenses. It was started in 2005 and it is being maintained to support diverse research projects and as a service to the overall research and artistic community.
In this demo we want to introduce Freesound to the multimedia community and show its potential as a research resource. We begin by describing some general aspects of Freesound, its architecture and functionalities, and then explain potential usages that this framework has for research applications.},
	keywords = {audio clips, freesound, online databases, sound},
	isbn = {978-1-4503-2404-5},
	doi = {10.1145/2502081.2502245},
	author = {Frederic Font and Gerard Roma and Xavier Serra}
}

@inproceedings{BarcelonaNoiseMonitoring,
  title={Barcelona noise monitoring network},
  author={Farr{\'e}s, J{\'u}lia Camps},
  booktitle={Proceedings of the EuroNoise},
  pages={218--220},
  year={2015}
}

@article{BarcelonaNoiseMonitoring2018,
  title={Issues and challenges to improve the Barcelona Noise Monitoring Network},
  author={Farr{\'e}s, J{\'u}lia Camps and Novas, Javier Casado},
  year={2018}
}



@article{MAIJALA2018258,
title = "Environmental noise monitoring using source classification in sensors",
journal = "Applied Acoustics",
volume = "129",
pages = "258 - 267",
year = "2018",
issn = "0003-682X",
doi = "https://doi.org/10.1016/j.apacoust.2017.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0003682X17307533",
author = "Panu Maijala and Zhao Shuyang and Toni Heittola and Tuomas Virtanen",
keywords = "Environmental noise monitoring, Acoustic pattern classification, Wireless sensor network, Cloud service",
}
@ARTICLE{Sigitia2016,
author={S. {Sigtia} and A. M. {Stark} and S. {Krstulović} and M. D. {Plumbley}},
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
title={Automatic Environmental Sound Recognition: Performance Versus Computational Cost},
year={2016},
volume={24},
number={11},
pages={2096-2107},
keywords={acoustic signal processing;Gaussian processes;mixture models;signal classification;speech recognition;support vector machines;automatic speech recognition;support vector machines;Gaussian mixture models;deep neural networks;sound classification performance;AESR algorithms;automatic environmental sound recognition algorithm;form factor;product pricing;embedded platforms;sound sensing;Internet of Things;performance cost;computational cost function;Computational efficiency;Speech;Speech recognition;Acoustics;Internet of things;IEEE transactions;Speech processing;Automatic environmental sound recognition;computational auditory scene analysis;deep learning;machine learning},
doi={10.1109/TASLP.2016.2592698},
ISSN={2329-9290},
month={Nov},
}

@article{sainath2015convolutional,
  title={Convolutional neural networks for small-footprint keyword spotting},
  author={Sainath, Tara and Parada, Carolina},
  year={2015}
}

@article{HelloEdge,
  title={Hello edge: Keyword spotting on microcontrollers},
  author={Zhang, Yundong and Suda, Naveen and Lai, Liangzhen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1711.07128},
  year={2017}
}

@article{lai2018not,
  title={Not all ops are created equal!},
  author={Lai, Liangzhen and Suda, Naveen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1801.04326},
  year={2018}
}

@misc{STEVAL-STLKT01V1,
title={STEVAL-STLKT01V1 product information},
author={STMicroelectronics},
url="https://www.st.com/en/evaluation-tools/steval-stlkt01v1.html",
}

@misc{STM32L476,
title={DS10198: STM32L476xx datasheet},
author={STMicroelectronics},
url="https://www.st.com/en/microcontrollers/stm32l476rg.html",
}

@misc{X-CUBE-AI-manual,
title={UM2526: Getting started with X-CUBE-AI Expansion Package for Artificial Intelligence (AI)},
author={STMicroelectronics},
url="https://www.st.com/resource/en/user_manual/dm00570145.pdf"
}

@misc{EdgeMLGithub,
title="Edge Machine Learning by Microsoft on Github",
url="https://github.com/Microsoft/EdgeML/"
}

@inproceedings{ProtoNN,
  title={Protomm: Compressed and accurate knn for resource-scarce devices},
  author={Gupta, Chirag and Suggala, Arun Sai and Goyal, Ankit and Simhadri, Harsha Vardhan and Paranjape, Bhargavi and Kumar, Ashish and Goyal, Saurabh and Udupa, Raghavendra and Varma, Manik and Jain, Prateek},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1331--1340},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{Bonsai,
  title={Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things},
  author={Kumar, Ashish and Goyal, Saurabh and Varma, Manik},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1935--1944},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{FastGRNN,
  title={FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network},
  author={Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9031--9042},
  year={2018}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}


@misc{librosa,
  author       = {Brian McFee and
                  Matt McVicar and
                  Stefan Balke and
                  Vincent Lostanlen and
                  Carl Thomé and
                  Colin Raffel and
                  Dana Lee and
                  Kyungyun Lee and
                  Oriol Nieto and
                  Frank Zalkow and
                  Dan Ellis and
                  Eric Battenberg and
                  Ryuichi Yamamoto and
                  Josh Moore and
                  Ziyao Wei and
                  Rachel Bittner and
                  Keunwoo Choi and
                  nullmightybofo and
                  Pius Friesch and
                  Fabian-Robert Stöter and
                  Thassilo and
                  Matt Vollrath and
                  Siddhartha Kumar Golu and
                  nehz and
                  Simon Waloschek and
                  Seth and
                  Rimvydas Naktinis and
                  Douglas Repetto and
                  Curtis "Fjord" Hawthorne and
                  CJ Carr},
  title        = {librosa/librosa: 0.6.3},
  month        = feb,
  year         = 2019,
  doi          = {10.5281/zenodo.2564164},
  url          = {https://doi.org/10.5281/zenodo.2564164}
}

@misc{FP-AI-SENSING1,
title={FP-AI-SENSING1 function pack},
author={STMicroelectronics},
url="https://www.st.com/en/embedded-software/fp-ai-sensing1.html",
}

@InProceedings{ST-FD-SOI,
author="Desoli, Giuseppe
and Tomaselli, Valeria
and Plebani, Emanuele
and Urlini, Giulio
and Pau, Danilo
and D'Alto, Viviana
and Majo, Tommaso
and De Ambroggi, Fabio
and Boesch, Thomas
and Singh, Surinder-pal
and Guidetti, Elio
and Chawla, Nitin",
editor="Blanc-Talon, Jacques
and Distante, Cosimo
and Philips, Wilfried
and Popescu, Dan
and Scheunders, Paul",
title="The Orlando Project: A 28 nm FD-SOI Low Memory Embedded Neural Network ASIC",
booktitle="Advanced Concepts for Intelligent Vision Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="217--227",
abstract="The recent success of neural networks in various computer vision tasks open the possibility to add visual intelligence to mobile and wearable devices; however, the stringent power requirements are unsuitable for networks run on embedded CPUs or GPUs. To address such challenges, STMicroelectronics developed the Orlando Project, a new and low power architecture for convolutional neural network acceleration suited for wearable devices. An important contribution to the energy usage is the storage and access to the neural network parameters. In this paper, we show that with adequate model compression schemes based on weight quantization and pruning, a whole AlexNet network can fit in the local memory of an embedded processor, thus avoiding additional system complexity and energy usage, with no or low impact on the accuracy of the network. Moreover, the compression methods work well across different tasks, e.g. image classification and object detection.",
isbn="978-3-319-48680-2"
}

@misc{emlearn,
  author       = {Jon Nordby},
  title        = {{emlearn: Machine Learning inference engine for 
                   Microcontrollers and Embedded Devices}},
  month        = mar,
  year         = 2019,
  doi          = {10.5281/zenodo.2589394},
  url          = {https://doi.org/10.5281/zenodo.2589394}
}
@online{EuNoiseDirective,
    author    = "",
    title     = "EU directive 2002/49/EC",
    url       = "http://ec.europa.eu/environment/noise/directive_en.htm",
}

@online{SONYC,
    title     = "Sound of New York (SONYC) homepage",
    url       = "http://wp.nyu.edu/sonyc",
    keywords  = "deployment",
}

@online{CENSE,
    title     = "CENSE project homepage",
    url       = "http://cense.ifsttar.fr/en/",
    keywords  = "deployment",
}

@inproceedings{CENSESensor,
  title={An innovative low cost sensor for urban sound monitoring},
  author={Ardouin, J{\'e}r{\'e}my and Charpentier, Ludovic and Lagrange, Mathieu and Gontier, F{\'e}lix and Fortin, Nicolas and Ecoti{\`e}re, David and Picaut, Judicael and Mietlicky, Christophe},
  booktitle={INTER-NOISE and NOISE-CON Congress and Conference Proceedings},
  volume={258},
  number={5},
  pages={2226--2237},
  year={2018},
  organization={Institute of Noise Control Engineering}
}

@article{EdgeL3,
  title={EdgeL3: Compressing L3-Net for Mote-Scale Urban Noise Monitoring},
  author={Kumari, Sangeeta and Roy, Dhrubojyoti and Cartwright, Mark and Bello, Juan Pablo and Arora, Anish},
  howpublished={\url=http://www.markcartwright.com/s/Kumari_2019.pdf}
}

@article{SONYC2019,
    author = "Bello, Juan P. and Silva, Claudio and Nov, Oded and Dubois, R. Luke and Arora, Anish and Salamon, Justin and Mydlarz, Charles and Doraiswamy, Harish",
    doi = "10.1145/3224204",
    title = "SONYC: A System for Monitoring, Analyzing, and Mitigating Urban Noise Pollution",
    abstract = "Noise is unwanted or harmful sound from environmental sources, including traffic, construction, industrial, and social activity. Noise pollution is one of the topmost quality-of-life concerns for urban residents in the U.S., with more than 70 million people nationwide exposed to noise levels beyond the limit the U.S. Environmental Protection Agency (EPA) considers harmful.12 Such levels have proven effects on health, including sleep disruption, hypertension, heart disease, and hearing loss.5,11,12 In addition, there is evidence of harmful effects on educational performance, with studies showing noise pollution causing learning and cognitive impairment in children, resulting in decreased memory capacity, reading skills, and test scores.",
    number = "2",
    month = "Feb",
    volume = "62",
    pages = "68-77",
    year = "2019",
    journal = "Communications of the ACM"
}
@misc{SONYC-UST,
  author       = {Mark Cartwright and
                  Ana Elisa Mendez Mendez and
                  Graham Dove and
                  Jason Cramer and
                  Vincent Lostanlen and
                  Ho-Hsiang Wu and
                  Justin Salamon and
                  Oded Nov and
                  Juan Pablo Bello},
  title        = {{SONYC Urban Sound Tagging (SONYC-UST): a 
                   multilabel dataset from an urban acoustic sensor
                   network}},
  month        = mar,
  year         = 2019,
  note         = {{This work is supported by National Science 
                   Foundation award 1544753.}},
  doi          = {10.5281/zenodo.2590742},
  url          = {https://doi.org/10.5281/zenodo.2590742}
}

@misc{Forurensningsloven,
    title="Forskrift om begrensning av forurensning, del 2. Støy",
    url="https://lovdata.no/dokument/SF/forskrift/2004-06-01-931/KAPITTEL_2#KAPITTEL_2",
    year={2004},
    keywords="legislation",
}

@Article{AudioCodingSensorGrid,
AUTHOR = {Gontier, Félix and Lagrange, Mathieu and Aumond, Pierre and Can, Arnaud and Lavandier, Catherine},
TITLE = {An Efficient Audio Coding Scheme for Quantitative and Qualitative Large Scale Acoustic Monitoring Using the Sensor Grid Approach},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2758},
URL = {http://www.mdpi.com/1424-8220/17/12/2758},
ISSN = {1424-8220},
DOI = {10.3390/s17122758},
}

@misc{IECSoundLevelMeters,
title="IEC 61672-1 Sound Level Meters, part 1: Specifications",
year={2013},
url="https://standards.globalspec.com/std/1634276/iec-61672-1",
}
@misc{ANSISoundLevelMeters,
title={ANSI S1.4-2014, Part 1: Specifications for Sound Level Meters},
year={2014},
author={Acoustical Society of America},
url="https://webstore.ansi.org/Standards/ASA/ANSIASAS12014PartIEC616722013"
}

@misc{IECPersonalSoundExposureMeters,
title="IEC 61252 Personal Sound Exposure Meters",
year={2017},
url="https://standards.globalspec.com/std/10153028/IEC%2061252",
}
@misc{IECOctaveBands,
title="IEC 61260-1:2014",
year={2014},
url="https://webstore.iec.ch/publication/5063",
}

@misc{ANSIOctaveBands,
title={ANSI S1.11-2004: Octave-Band and Fractional-Octave-Band Analog and Digital Filters},
year={2004},
url={https://webstore.ansi.org/standards/asa/ansiasas1112004r2009}
}

@Article{AudioCodingSensorGrid,
AUTHOR = {Gontier, Félix and Lagrange, Mathieu and Aumond, Pierre and Can, Arnaud and Lavandier, Catherine},
TITLE = {An Efficient Audio Coding Scheme for Quantitative and Qualitative Large Scale Acoustic Monitoring Using the Sensor Grid Approach},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2758},
URL = {http://www.mdpi.com/1424-8220/17/12/2758},
ISSN = {1424-8220},
DOI = {10.3390/s17122758},
}

@article{IncrementalNetworkQuantization,
  author    = {Aojun Zhou and
               Anbang Yao and
               Yiwen Guo and
               Lin Xu and
               Yurong Chen},
  title     = {Incremental Network Quantization: Towards Lossless CNNs with Low-Precision
               Weights},
  journal   = {CoRR},
  volume    = {abs/1702.03044},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.03044},
  archivePrefix = {arXiv},
  eprint    = {1702.03044},
  timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhouYGXC17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{BatchNormalization,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{smith1997scientist,
  title={The scientist and engineer's guide to digital signal processing},
  author={Smith, Steven W and others},
  year={1997},
  publisher={California Technical Pub. San Diego}
}


@article{Mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@article{Cutout,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1708.04552},
  year={2017}
}

@InProceedings{Mixup-ASC,
author="Xu, Kele
and Feng, Dawei
and Mi, Haibo
and Zhu, Boqing
and Wang, Dezhi
and Zhang, Lilun
and Cai, Hengxing
and Liu, Shuwen",
editor="Hong, Richang
and Cheng, Wen-Huang
and Yamasaki, Toshihiko
and Wang, Meng
and Ngo, Chong-Wah",
title="Mixup-Based Acoustic Scene Classification Using Multi-channel Convolutional Neural Network",
booktitle="Advances in Multimedia Information Processing -- PCM 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="14--23",
isbn="978-3-030-00764-5"
}


@inproceedings{Xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@article{NoiseStressConcept,
IDS = {NoiseSeverityPyramid},
author = {Babisch, Wolfgang.},
title =  {The noise/stress concept, risk assessment and research needs},
journal  ={Noise and Health},
volume ={4},
number ={16},
pages  = {1-11},
year  = {2002},
URL ={http://www.noiseandhealth.org/article.asp?issn=1463-1741;year=2002;volume=4;issue=16;spage=1;epage=11;aulast=Babisch;t=6},
eprint ={http://www.noiseandhealth.org/article.asp?issn=1463-1741;year=2002;volume=4;issue=16;spage=1;epage=11;aulast=Babisch;t=6}
}

@book{ComputationalAnalysisSound,
author = {Virtanen, Tuomas and Plumbley, Mark and Ellis, Dan},
year = {2017},
month = {09},
pages = {1-422},
title = {Computational Analysis of Sound Scenes and Events},
journal = {Computational Analysis of Sound Scenes and Events},
doi = {10.1007/978-3-319-63450-0},
ISBN = "978-3-319-63450-0",
}

@inproceedings{PiczakCNN,
  title={Environmental sound classification with convolutional neural networks},
  author={Piczak, Karol J},
  booktitle={2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@article{SB-CNN,
  author    = {Justin Salamon and
               Juan Pablo Bello},
  title     = {Deep Convolutional Neural Networks and Data Augmentation for Environmental
               Sound Classification},
  journal   = {CoRR},
  volume    = {abs/1608.04363},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.04363},
  archivePrefix = {arXiv},
  eprint    = {1608.04363},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SalamonB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{D-CNN,
author = {Zhang, Xiaohu and Zou, Yuexian and Shi, Wei},
year = {2017},
month = {08},
pages = {1-5},
title = {Dilated convolution neural network with LeakyReLU for environmental sound classification},
doi = {10.1109/ICDSP.2017.8096153}
}

@inproceedings{EnvNet,
author = {Tokozume, Yuji and Harada, Tatsuya},
year = {2017},
month = {03},
pages = {2721-2725},
title = {Learning environmental sounds with end-to-end convolutional neural network},
doi = {10.1109/ICASSP.2017.7952651}
}

@article{EnvNet2,
  title={Learning from between-class examples for deep sound recognition},
  author={Tokozume, Yuji and Ushiku, Yoshitaka and Harada, Tatsuya},
  journal={arXiv preprint arXiv:1711.10282},
  year={2017}
}

@inproceedings{ESC-mixup,
  title={Deep convolutional neural network with mixup for environmental sound classification},
  author={Zhang, Zhichao and Xu, Shugong and Cao, Shan and Zhang, Shunqing},
  booktitle={Chinese Conference on Pattern Recognition and Computer Vision (PRCV)},
  pages={356--367},
  year={2018},
  organization={Springer}
}

@inproceedings{LD-CNN,
  title={LD-CNN: A Lightweight Dilated Convolutional Neural Network for Environmental Sound Classification},
  author={Zhang, Xiaohu and Zou, Yuexian and Wang, Wenwu},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},
  pages={373--378},
  year={2018},
  organization={IEEE}
}

@article{AclNet,
  title={AclNet: efficient end-to-end audio classification CNN},
  author={Huang, Jonathan J and Leanos, Juan Jose Alvarado},
  journal={arXiv preprint arXiv:1811.06669},
  year={2018}
}


@article{eGRU,
  title={An Optimized Recurrent Unit for Ultra-Low-Power Keyword Spotting},
  author={Amoh, Justice and Odame, Kofi},
  journal={arXiv preprint arXiv:1902.05026},
  year={2019}
}


@INPROCEEDINGS{VeryDeepESC,
author={W. {Dai} and C. {Dai} and S. {Qu} and J. {Li} and S. {Das}},
booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Very deep convolutional neural networks for raw waveforms},
year={2017},
volume={},
number={},
pages={421-425},
doi={10.1109/ICASSP.2017.7952190},
ISSN={2379-190X},
month={March},
}

@InProceedings{WSNet,
  title = 	 {WSNet: Compact and Efficient Networks Through Weight Sampling},
  author = 	 {Jin, Xiaojie and Yang, Yingzhen and Xu, Ning and Yang, Jianchao and Jojic, Nebojsa and Feng, Jiashi and Yan, Shuicheng},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2352--2361},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/jin18d/jin18d.pdf},
  url = 	 {http://proceedings.mlr.press/v80/jin18d.html}
}


@article{SqueezeNet,
    Author = {Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
    Title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$0.5MB model size},
    Journal = {arXiv:1602.07360},
    Year = {2016}
}

@article{SqueezeNext,
  author    = {Amir Gholami and
               Kiseok Kwon and
               Bichen Wu and
               Zizheng Tai and
               Xiangyu Yue and
               Peter H. Jin and
               Sicheng Zhao and
               Kurt Keutzer},
  title     = {SqueezeNext: Hardware-Aware Neural Network Design},
  journal   = {CoRR},
  volume    = {abs/1803.10615},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.10615},
  archivePrefix = {arXiv},
  eprint    = {1803.10615},
  timestamp = {Mon, 13 Aug 2018 16:46:45 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-10615},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Effnet,
  title={Effnet: An efficient structure for convolutional neural networks},
  author={Freeman, Ido and Roese-Koerner, Lutz and Kummert, Anton},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)},
  pages={6--10},
  year={2018},
  organization={IEEE}
}


@article{Ristretto,
  title={Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in Convolutional Neural Networks},
  author={Gysel, Philipp and Pimentel, Jon and Motamedi, Mohammad and Ghiasi, Soheil},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2018},
  publisher={IEEE},
  doi={10.1109/TNNLS.2018.2808319}
}

@online{TensorFlowGroupConvolutionPR,
    title="Tensorflow Github #25818: Add support for cudnn's group convolution",
    url={https://github.com/tensorflow/tensorflow/pull/25818}
}

@article{Mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{Mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018}
}


@inproceedings{Shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{AlexNet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}


@online{ConvolutionsIllustrated,
    author={Yusuke Uchida},
    title="Why MobileNet and Its Variants (e.g. ShuffleNet) Are Fast",
    url="https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d",
}


@online{KendryteK210Datasheet,
    title="K210 datasheet [English]",
    author="Kendryte",
    url="https://s3.cn-north-1.amazonaws.com.cn/dl.kendryte.com/documents/kendryte_datasheet_20181011163248_en.pdf"
}

@online{GAP8vsARM,
    title="GAP8 performance versus ARM M7 on Embedded CNNs",
    author="Greenwaves Technologies",
    url="https://greenwaves-technologies.com/gap8-versus-arm-m7-embedded-cnns",
}

@online{ST-DCNN-accelerator,
    title="Demo AI slides @ STMicroelectronics NV 2018 Capital Markets Day",
    year={2018},
    month={05},
    day={15},
    author="ST Microelectronics",
    url="http://investors.st.com/events/event-details/stmicroelectronics-nv-2018-capital-markets-day",
}
@online{ARMHeliumAnnouncement,
    title="Next-generation Armv8.1-M architecture: Delivering enhanced machine learning and signal processing for the smallest embedded devices",
    year={2019},
    month={02},
    day={14},
    url="https://www.arm.com/company/news/2019/02/next-generation-armv8-1-m-architecture",
}

