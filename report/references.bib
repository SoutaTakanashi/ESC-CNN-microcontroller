@article{TensorFlowSpeechCommands,
title={Speech Commands: A public dataset for single-word speech recognition.},
author={Warden, Pete},
journal={Dataset available from http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz},
year={2017}
}
@article{CMSISNN,
  author    = {Liangzhen Lai and
               Naveen Suda and
               Vikas Chandra},
  title     = {{CMSIS-NN:} Efficient Neural Network Kernels for Arm Cortex-M CPUs},
  journal   = {CoRR},
  volume    = {abs/1801.06601},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.06601},
  archivePrefix = {arXiv},
  eprint    = {1801.06601},
  timestamp = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-06601},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{KeywordSpottingMFCCSettings,
author={M. Shahnawaz and E. Plebani and I. Guaneri and D. Pau and M. Marcon},
booktitle={2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
title={Studying the Effects of Feature Extraction Settings on the Accuracy and Memory Requirements of Neural Networks for Keyword Spotting},
year={2018},
volume={},
number={},
pages={1-6},
keywords={Feature extraction;Speech recognition;Hidden Markov models;Random access memory;Recurrent neural networks;Computer architecture},
doi={10.1109/ICCE-Berlin.2018.8576243},
ISSN={2166-6822},
month={Sep.},}
@article{Veniat2018StochasticAN,
  title={Stochastic Adaptive Neural Architecture Search for Keyword Spotting},
  author={Tom V'eniat and Olivier Schwander and Ludovic Denoyer},
  journal={CoRR},
  year={2018},
  volume={abs/1811.06753}
}
@article{Tang2018AnEA,
  title={An Experimental Analysis of the Power Consumption of Convolutional Neural Networks for Keyword Spotting},
  author={Raphael Tang and Weijie Wang and Zhucheng Tu and Jimmy Lin},
  journal={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2018},
  pages={5479-5483}
}
@Inproceedings{FastGRNN,
author = {Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
title = {FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network},
year = {2018},
month = {December},
url = {https://www.microsoft.com/en-us/research/publication/fastgrnn-a-fast-accurate-stable-and-tiny-kilobyte-sized-gated-recurrent-neural-network/},
}
@inproceedings{UrbanSound8k,
Address = {Orlando, FL, USA},
Author = {Salamon, J. and Jacoby, C. and Bello, J. P.},
Booktitle = {22nd ACM International Conference on Multimedia (ACM-MM'14)},
Month = {Nov.},
Pages = {1041--1044},
Title = {A Dataset and Taxonomy for Urban Sound Research},
Year = {2014},
}

@conference{Freesound,
	title = {Freesound Technical Demo},
	booktitle = {ACM International Conference on Multimedia (MM{\textquoteright}13)},
	year = {2013},
	month = {21/10/2013},
	pages = {411-412},
	publisher = {ACM},
	organization = {ACM},
	address = {Barcelona, Spain},
	abstract = {Freesound is an online collaborative sound database where people with diverse interests share recorded sound samples under Creative Commons licenses. It was started in 2005 and it is being maintained to support diverse research projects and as a service to the overall research and artistic community.
In this demo we want to introduce Freesound to the multimedia community and show its potential as a research resource. We begin by describing some general aspects of Freesound, its architecture and functionalities, and then explain potential usages that this framework has for research applications.},
	keywords = {audio clips, freesound, online databases, sound},
	isbn = {978-1-4503-2404-5},
	doi = {10.1145/2502081.2502245},
	author = {Frederic Font and Gerard Roma and Xavier Serra}
}

@article{MAIJALA2018258,
title = "Environmental noise monitoring using source classification in sensors",
journal = "Applied Acoustics",
volume = "129",
pages = "258 - 267",
year = "2018",
issn = "0003-682X",
doi = "https://doi.org/10.1016/j.apacoust.2017.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0003682X17307533",
author = "Panu Maijala and Zhao Shuyang and Toni Heittola and Tuomas Virtanen",
keywords = "Environmental noise monitoring, Acoustic pattern classification, Wireless sensor network, Cloud service",
}
@ARTICLE{Sigitia2016,
author={S. {Sigtia} and A. M. {Stark} and S. {KrstuloviÄ‡} and M. D. {Plumbley}},
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
title={Automatic Environmental Sound Recognition: Performance Versus Computational Cost},
year={2016},
volume={24},
number={11},
pages={2096-2107},
keywords={acoustic signal processing;Gaussian processes;mixture models;signal classification;speech recognition;support vector machines;automatic speech recognition;support vector machines;Gaussian mixture models;deep neural networks;sound classification performance;AESR algorithms;automatic environmental sound recognition algorithm;form factor;product pricing;embedded platforms;sound sensing;Internet of Things;performance cost;computational cost function;Computational efficiency;Speech;Speech recognition;Acoustics;Internet of things;IEEE transactions;Speech processing;Automatic environmental sound recognition;computational auditory scene analysis;deep learning;machine learning},
doi={10.1109/TASLP.2016.2592698},
ISSN={2329-9290},
month={Nov},}
@misc{STEVAL-STLKT01V1,
author='STMicroelectronics',
url="https://www.st.com/en/evaluation-tools/steval-stlkt01v1.html"
}

