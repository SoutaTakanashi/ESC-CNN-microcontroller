
@book{WHONoiseBurden2018,
title="Burden of disease from environmental noise - Quantification of healthy life years lost in Europe",
author="WHO Regional Office for Europe",
year={2018},
ISBN={978 92 890 0229 5},
url="https://www.who.int/quantifying_ehimpacts/publications/e94888/en/",
}

@misc{WHONoiseGuidelines2018,
title="Environmental Noise Guidelines for the European Region",
author="WHO Regional Office for Europe",
year={2018},
ISBN={978 92 890 5356 3},
url="http://www.euro.who.int/en/publications/abstracts/environmental-noise-guidelines-for-the-european-region-2018",
}

@article{TensorFlowSpeechCommands,
title={Speech Commands: A public dataset for single-word speech recognition.},
author={Warden, Pete},
journal={Dataset available from http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz},
year={2017}
}
@article{CMSIS-NN,
  author    = {Liangzhen Lai and
               Naveen Suda and
               Vikas Chandra},
  title     = {{CMSIS-NN:} Efficient Neural Network Kernels for Arm Cortex-M CPUs},
  journal   = {CoRR},
  volume    = {abs/1801.06601},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.06601},
  archivePrefix = {arXiv},
  eprint    = {1801.06601},
  timestamp = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-06601},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@online{MbedHomepage,
    title="ARM Mbed project homepage",
    url="https://www.mbed.com",
}

@online{uTensor,
author={Neil Tan},
title={uTensor: AI Inference library based on mbed and TensorFlow},
}

@misc{Keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}

@online{LaunchingTensorflowLiteMicrocontrollers,
title={Launching TensorFlow Lite for Microcontrollers},
author={Pete Warden},
url={https://petewarden.com/2019/03/07/launching-tensorflow-lite-for-microcontrollers/},
year={2019},
month={03},  
}

@misc{MP3Standard,
    title="ISO/IEC 11172-3:1993 Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s -- Part 3: Audio",
    author={International Electrotechnical Commission JTC 1/SC 29},
    url={https://www.iso.org/standard/22412.html},
}

@misc{WAVspecification,
    title="WAVE specifications, Version 1.0, 1991-08",
    author={Microsoft},
    year={1991},
}

@online{FLACHomepage,
    title="FLAC project homepage (Free Lossless Audio Codec)",
    url="https://xiph.org/flac/",
    author={Xiph.Org Foundation},
}

@misc{AudioCDspecification,
    title="IEC 60908:1999 Audio recording - Compact disc digital audio system",
    author="International Electrotechnical Commission TC 100",
    url="https://webstore.iec.ch/publication/3885",
    year={1999},
}

@article{STFTmodifications,
  title={Short term spectral analysis, synthesis, and modification by discrete Fourier transform},
  author={Allen, Jonathan},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={25},
  number={3},
  pages={235--238},
  year={1977},
  publisher={IEEE}
}

@article{GriffinLimSpectrogramInversion,
  title={Signal estimation from modified short-time Fourier transform},
  author={Griffin, Daniel and Lim, Jae},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={32},
  number={2},
  pages={236--243},
  year={1984},
  publisher={IEEE}
}

@article{MCNNSpectrogramInversion,
  title={Fast spectrogram inversion using multi-head convolutional neural networks},
  author={Ar{\i}k, Sercan {\"O} and Jun, Heewoo and Diamos, Gregory},
  journal={IEEE Signal Processing Letters},
  volume={26},
  number={1},
  pages={94--98},
  year={2019},
  publisher={IEEE}
}


@article{huzaifah2017comparison,
  title={Comparison of time-frequency representations for environmental sound classification using convolutional neural networks},
  author={Huzaifah, Muhammad},
  journal={arXiv preprint arXiv:1706.07156},
  year={2017}
}

@article{StowellBirdUnsupervisedFeatureLearning,
 title = {Automatic large-scale classification of bird sounds is strongly improved by unsupervised feature learning},
 author = {Stowell, Dan and Plumbley, Mark D.},
 year = 2014,
 month = jul,
 keywords = {Bioacoustics, Machine learning, Birds, Classification, Vocalisation, Birdsong},
 volume = 2,
 pages = {e488},
 journal = {PeerJ},
 issn = {2167-8359},
 url = {https://doi.org/10.7717/peerj.488},
 doi = {10.7717/peerj.488}
}

@article{anusuya2011front,
  title={Front end analysis of speech recognition: a review},
  author={Anusuya, MA and Katti, SK},
  journal={International Journal of Speech Technology},
  volume={14},
  number={2},
  pages={99--145},
  year={2011},
  publisher={Springer}
}

@inproceedings{WeaklyLabeledAEDMIL,
  title={Audio event detection using weakly labeled data},
  author={Kumar, Anurag and Raj, Bhiksha},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={1038--1047},
  year={2016},
  organization={ACM}
}


@article{AdaptivePoolingWeaklyLabeled,
  title={Adaptive pooling operators for weakly labeled sound event detection},
  author={McFee, Brian and Salamon, Justin and Bello, Juan Pablo},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)},
  volume={26},
  number={11},
  pages={2180--2193},
  year={2018},
  publisher={IEEE Press}
}

@article{morfi2018dcase,
  title={Data-efficient weakly supervised learning for low-resource audio event detection using deep learning},
  author={Morfi, Veronica and Stowell, Dan},
  journal={arXiv preprint arXiv:1807.06972},
  year={2018}
}


@article{Mnasnet,
  title={Mnasnet: Platform-aware neural architecture search for mobile},
  author={Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Le, Quoc V},
  journal={arXiv preprint arXiv:1807.11626},
  year={2018}
}


@INPROCEEDINGS{KeywordSpottingMFCCSettings,
author={M. Shahnawaz and E. Plebani and I. Guaneri and D. Pau and M. Marcon},
booktitle={2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
title={Studying the Effects of Feature Extraction Settings on the Accuracy and Memory Requirements of Neural Networks for Keyword Spotting},
year={2018},
volume={},
number={},
pages={1-6},
keywords={Feature extraction;Speech recognition;Hidden Markov models;Random access memory;Recurrent neural networks;Computer architecture},
doi={10.1109/ICCE-Berlin.2018.8576243},
ISSN={2166-6822},
month={Sep.},}
@article{Veniat2018StochasticAN,
  title={Stochastic Adaptive Neural Architecture Search for Keyword Spotting},
  author={Tom V'eniat and Olivier Schwander and Ludovic Denoyer},
  journal={CoRR},
  year={2018},
  volume={abs/1811.06753}
}
@article{Tang2018AnEA,
  title={An Experimental Analysis of the Power Consumption of Convolutional Neural Networks for Keyword Spotting},
  author={Raphael Tang and Weijie Wang and Zhucheng Tu and Jimmy Lin},
  journal={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2018},
  pages={5479-5483}
}
@Inproceedings{FastGRNN,
author = {Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
title = {FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network},
year = {2018},
month = {December},
url = {https://www.microsoft.com/en-us/research/publication/fastgrnn-a-fast-accurate-stable-and-tiny-kilobyte-sized-gated-recurrent-neural-network/},
}
@inproceedings{UrbanSound8k,
Address = {Orlando, FL, USA},
Author = {Salamon, J. and Jacoby, C. and Bello, J. P.},
Booktitle = {22nd ACM International Conference on Multimedia (ACM-MM'14)},
Month = {Nov.},
Pages = {1041--1044},
Title = {A Dataset and Taxonomy for Urban Sound Research},
Year = {2014},
}

@article{chu2009environmental,
  title={Environmental sound recognition with time--frequency audio features},
  author={Chu, Selina and Narayanan, Shrikanth and Kuo, C-C Jay},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={17},
  number={6},
  pages={1142--1158},
  year={2009},
  publisher={IEEE}
}

@inproceedings{medhat2017masked,
  aka="YorNoise",
  title={Masked conditional neural networks for environmental sound classification},
  author={Medhat, Fady and Chesmore, David and Robinson, John},
  booktitle={International Conference on Innovative Techniques and Applications of Artificial Intelligence},
  pages={21--33},
  year={2017},
  organization={Springer}
}

@inproceedings{TUT2017dataset,
    author = "Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas",
    title = "{TUT} Database for Acoustic Scene Classification and Sound Event Detection",
    abstract = "We introduce TUT Acoustic Scenes 2016 database for environmental sound research, consisting ofbinaural recordings from 15 different acoustic environments. A subset of this database, called TUT Sound Events 2016, contains annotations for individual sound events, specifically created for sound event detection. TUT Sound Events 2016 consists of residential area and home environments, and is manually annotated to mark onset, offset and label of sound events. In this paper we present the recording and annotation procedure, the database content, a recommended cross-validation setup and performance of supervised acoustic scene classification system and event detection baseline system using mel frequency cepstral coefficients and Gaussian mixture models. The database is publicly released to provide support for algorithm development and common ground for comparison of different techniques.",
    year = "2016",
    booktitle = "24th European Signal Processing Conference 2016 (EUSIPCO 2016)",
    address = "Budapest, Hungary"
}

@conference{Freesound,
	title = {Freesound Technical Demo},
	booktitle = {ACM International Conference on Multimedia (MM{\textquoteright}13)},
	year = {2013},
	month = {21/10/2013},
	pages = {411-412},
	publisher = {ACM},
	organization = {ACM},
	address = {Barcelona, Spain},
	abstract = {Freesound is an online collaborative sound database where people with diverse interests share recorded sound samples under Creative Commons licenses. It was started in 2005 and it is being maintained to support diverse research projects and as a service to the overall research and artistic community.
In this demo we want to introduce Freesound to the multimedia community and show its potential as a research resource. We begin by describing some general aspects of Freesound, its architecture and functionalities, and then explain potential usages that this framework has for research applications.},
	keywords = {audio clips, freesound, online databases, sound},
	isbn = {978-1-4503-2404-5},
	doi = {10.1145/2502081.2502245},
	author = {Frederic Font and Gerard Roma and Xavier Serra}
}

@inproceedings{BarcelonaNoiseMonitoring,
  title={Barcelona noise monitoring network},
  author={Farr{\'e}s, J{\'u}lia Camps},
  booktitle={Proceedings of the EuroNoise},
  pages={218--220},
  year={2015}
}

@article{BarcelonaNoiseMonitoring2018,
  title={Issues and challenges to improve the Barcelona Noise Monitoring Network},
  author={Farr{\'e}s, J{\'u}lia Camps and Novas, Javier Casado},
  year={2018}
}



@article{MAIJALA2018258,
title = "Environmental noise monitoring using source classification in sensors",
journal = "Applied Acoustics",
volume = "129",
pages = "258 - 267",
year = "2018",
issn = "0003-682X",
doi = "https://doi.org/10.1016/j.apacoust.2017.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0003682X17307533",
author = "Panu Maijala and Zhao Shuyang and Toni Heittola and Tuomas Virtanen",
keywords = "Environmental noise monitoring, Acoustic pattern classification, Wireless sensor network, Cloud service",
}
@ARTICLE{Sigitia2016,
author={S. {Sigtia} and A. M. {Stark} and S. {Krstulović} and M. D. {Plumbley}},
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
title={Automatic Environmental Sound Recognition: Performance Versus Computational Cost},
year={2016},
volume={24},
number={11},
pages={2096-2107},
keywords={acoustic signal processing;Gaussian processes;mixture models;signal classification;speech recognition;support vector machines;automatic speech recognition;support vector machines;Gaussian mixture models;deep neural networks;sound classification performance;AESR algorithms;automatic environmental sound recognition algorithm;form factor;product pricing;embedded platforms;sound sensing;Internet of Things;performance cost;computational cost function;Computational efficiency;Speech;Speech recognition;Acoustics;Internet of things;IEEE transactions;Speech processing;Automatic environmental sound recognition;computational auditory scene analysis;deep learning;machine learning},
doi={10.1109/TASLP.2016.2592698},
ISSN={2329-9290},
month={Nov},
}

@article{sainath2015convolutional,
  title={Convolutional neural networks for small-footprint keyword spotting},
  author={Sainath, Tara and Parada, Carolina},
  year={2015}
}

@article{HelloEdge,
  title={Hello edge: Keyword spotting on microcontrollers},
  author={Zhang, Yundong and Suda, Naveen and Lai, Liangzhen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1711.07128},
  year={2017}
}

@article{lai2018not,
  title={Not all ops are created equal!},
  author={Lai, Liangzhen and Suda, Naveen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1801.04326},
  year={2018}
}

@misc{STEVAL-STLKT01V1,
title={STEVAL-STLKT01V1 product information},
author={STMicroelectronics},
url="https://www.st.com/en/evaluation-tools/steval-stlkt01v1.html",
}

@misc{STM32L476,
title={DS10198: STM32L476xx datasheet},
author={STMicroelectronics},
url="https://www.st.com/en/microcontrollers/stm32l476rg.html",
}

@article{Caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@online{X-CUBE-AI,
title="X-CUBE-AI: AI expansion pack for STM32CubeMX",
url="https://www.st.com/en/embedded-software/x-cube-ai.html",
year={2019},
}

@misc{X-CUBE-AI-manual,
title={UM2526: Getting started with X-CUBE-AI Expansion Package for Artificial Intelligence (AI)},
author={STMicroelectronics},
url="https://www.st.com/resource/en/user_manual/dm00570145.pdf"
}

@misc{EdgeMLGithub,
title="Edge Machine Learning by Microsoft on Github",
url="https://github.com/Microsoft/EdgeML/"
}

@inproceedings{ProtoNN,
  title={Protomm: Compressed and accurate knn for resource-scarce devices},
  author={Gupta, Chirag and Suggala, Arun Sai and Goyal, Ankit and Simhadri, Harsha Vardhan and Paranjape, Bhargavi and Kumar, Ashish and Goyal, Saurabh and Udupa, Raghavendra and Varma, Manik and Jain, Prateek},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1331--1340},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{Bonsai,
  title={Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things},
  author={Kumar, Ashish and Goyal, Saurabh and Varma, Manik},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1935--1944},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{FastGRNN,
  title={FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network},
  author={Kusupati, Aditya and Singh, Manish and Bhatia, Kush and Kumar, Ashish and Jain, Prateek and Varma, Manik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9031--9042},
  year={2018}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}


@misc{librosa,
  author       = {Brian McFee and
                  Matt McVicar and
                  Stefan Balke and
                  Vincent Lostanlen and
                  Carl Thomé and
                  Colin Raffel and
                  Dana Lee and
                  Kyungyun Lee and
                  Oriol Nieto and
                  Frank Zalkow and
                  Dan Ellis and
                  Eric Battenberg and
                  Ryuichi Yamamoto and
                  Josh Moore and
                  Ziyao Wei and
                  Rachel Bittner and
                  Keunwoo Choi and
                  nullmightybofo and
                  Pius Friesch and
                  Fabian-Robert Stöter and
                  Thassilo and
                  Matt Vollrath and
                  Siddhartha Kumar Golu and
                  nehz and
                  Simon Waloschek and
                  Seth and
                  Rimvydas Naktinis and
                  Douglas Repetto and
                  Curtis "Fjord" Hawthorne and
                  CJ Carr},
  title        = {librosa/librosa: 0.6.3},
  month        = feb,
  year         = 2019,
  doi          = {10.5281/zenodo.2564164},
  url          = {https://doi.org/10.5281/zenodo.2564164}
}

@misc{FP-AI-SENSING1,
title={FP-AI-SENSING1 function pack},
author={STMicroelectronics},
url="https://www.st.com/en/embedded-software/fp-ai-sensing1.html",
}

@InProceedings{ST-FD-SOI,
author="Desoli, Giuseppe
and Tomaselli, Valeria
and Plebani, Emanuele
and Urlini, Giulio
and Pau, Danilo
and D'Alto, Viviana
and Majo, Tommaso
and De Ambroggi, Fabio
and Boesch, Thomas
and Singh, Surinder-pal
and Guidetti, Elio
and Chawla, Nitin",
editor="Blanc-Talon, Jacques
and Distante, Cosimo
and Philips, Wilfried
and Popescu, Dan
and Scheunders, Paul",
title="The Orlando Project: A 28 nm FD-SOI Low Memory Embedded Neural Network ASIC",
booktitle="Advanced Concepts for Intelligent Vision Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="217--227",
abstract="The recent success of neural networks in various computer vision tasks open the possibility to add visual intelligence to mobile and wearable devices; however, the stringent power requirements are unsuitable for networks run on embedded CPUs or GPUs. To address such challenges, STMicroelectronics developed the Orlando Project, a new and low power architecture for convolutional neural network acceleration suited for wearable devices. An important contribution to the energy usage is the storage and access to the neural network parameters. In this paper, we show that with adequate model compression schemes based on weight quantization and pruning, a whole AlexNet network can fit in the local memory of an embedded processor, thus avoiding additional system complexity and energy usage, with no or low impact on the accuracy of the network. Moreover, the compression methods work well across different tasks, e.g. image classification and object detection.",
isbn="978-3-319-48680-2"
}

@misc{emlearn,
  author       = {Jon Nordby},
  title        = {{emlearn: Machine Learning inference engine for 
                   Microcontrollers and Embedded Devices}},
  month        = mar,
  year         = 2019,
  doi          = {10.5281/zenodo.2589394},
  url          = {https://doi.org/10.5281/zenodo.2589394}
}
@online{EuNoiseDirective,
    author    = "",
    title     = "EU directive 2002/49/EC",
    url       = "http://ec.europa.eu/environment/noise/directive_en.htm",
}

@online{SONYC,
    title     = "Sound of New York (SONYC) homepage",
    url       = "http://wp.nyu.edu/sonyc",
    keywords  = "deployment",
}

@online{SONYC-CPS,
title="Citizen Scientists Can Help Mitigate Noise Pollution",
url="https://steinhardt.nyu.edu/site/ataglance/2019/02/citizen-scientists-can-help-mitigate-noise-pollution.html",
year={2019},
}

@online{CENSE,
    title     = "CENSE project homepage",
    url       = "http://cense.ifsttar.fr/en/",
    keywords  = "deployment",
}

@inproceedings{CENSESensor,
  title={An innovative low cost sensor for urban sound monitoring},
  author={Ardouin, J{\'e}r{\'e}my and Charpentier, Ludovic and Lagrange, Mathieu and Gontier, F{\'e}lix and Fortin, Nicolas and Ecoti{\`e}re, David and Picaut, Judicael and Mietlicky, Christophe},
  booktitle={INTER-NOISE and NOISE-CON Congress and Conference Proceedings},
  volume={258},
  number={5},
  pages={2226--2237},
  year={2018},
  organization={Institute of Noise Control Engineering}
}

@article{EdgeL3,
  title={EdgeL3: Compressing L3-Net for Mote-Scale Urban Noise Monitoring},
  author={Kumari, Sangeeta and Roy, Dhrubojyoti and Cartwright, Mark and Bello, Juan Pablo and Arora, Anish},
  howpublished={\url=http://www.markcartwright.com/s/Kumari_2019.pdf}
}

@article{SONYC2019,
    author = "Bello, Juan P. and Silva, Claudio and Nov, Oded and Dubois, R. Luke and Arora, Anish and Salamon, Justin and Mydlarz, Charles and Doraiswamy, Harish",
    doi = "10.1145/3224204",
    title = "SONYC: A System for Monitoring, Analyzing, and Mitigating Urban Noise Pollution",
    abstract = "Noise is unwanted or harmful sound from environmental sources, including traffic, construction, industrial, and social activity. Noise pollution is one of the topmost quality-of-life concerns for urban residents in the U.S., with more than 70 million people nationwide exposed to noise levels beyond the limit the U.S. Environmental Protection Agency (EPA) considers harmful.12 Such levels have proven effects on health, including sleep disruption, hypertension, heart disease, and hearing loss.5,11,12 In addition, there is evidence of harmful effects on educational performance, with studies showing noise pollution causing learning and cognitive impairment in children, resulting in decreased memory capacity, reading skills, and test scores.",
    number = "2",
    month = "Feb",
    volume = "62",
    pages = "68-77",
    year = "2019",
    journal = "Communications of the ACM"
}
@misc{SONYC-UST,
  author       = {Mark Cartwright and
                  Ana Elisa Mendez Mendez and
                  Graham Dove and
                  Jason Cramer and
                  Vincent Lostanlen and
                  Ho-Hsiang Wu and
                  Justin Salamon and
                  Oded Nov and
                  Juan Pablo Bello},
  title        = {{SONYC Urban Sound Tagging (SONYC-UST): a 
                   multilabel dataset from an urban acoustic sensor
                   network}},
  month        = mar,
  year         = 2019,
  note         = {{This work is supported by National Science 
                   Foundation award 1544753.}},
  doi          = {10.5281/zenodo.2590742},
  url          = {https://doi.org/10.5281/zenodo.2590742}
}


@online{DCASE2017Task4,
title="DCASE2017 task 4, Large-scale weakly supervised sound event detection for smart cars",
url="http://www.cs.tut.fi/sgn/arg/dcase2017/challenge/task-large-scale-sound-event-detection",
year={2017},
}

@online{DCASE2017Task2,
url="http://www.cs.tut.fi/sgn/arg/dcase2017/challenge/task-rare-sound-event-detection",
title="DCASE2017 task 2, Rare Sound Event Detection",
year={2017},
}

@online{DCASE2017Task1,
url="http://www.cs.tut.fi/sgn/arg/dcase2017/challenge/task-acoustic-scene-classification",
title="DCASE2017 task 1, Acoustic Scene Classification",
year={2017},
}

@online{DCASE2019Task5,
title="DCASE2019 task 5, Urban Sound Tagging",
url="http://dcase.community/challenge2019/task-urban-sound-tagging",
year={2019},
}

@online{DCASE2018Task2,
url="http://dcase.community/challenge2018/task-general-purpose-audio-tagging",
title="DCASE2018 task 2, General Purpose Audio Tagging using AudioSet ontology",
year={2018},
}


@online{STM32F103decap,
url="https://zeptobars.com/en/read/STM-STM32F103VGT6",
title="STM32F103VGT6 : Weekend die-shot",
year={2012},
month={12},
day={16},
}

@misc{ST-Orlando-MPSoc17,
title="A 2.9 TOPS/W Deep Convolutional Neural Network SoC in FD-SOI 28nm for Intelligent Embedded Systems",
author="Danilo Pau",
url="http://www.mpsoc-forum.org/previous/2017/speakers/page/Danilo_Pau.html",
year={2017},
}

@online{ICInsightsMCUSales,
url="http://www.icinsights.com/news/bulletins/MCUs-Sales-To-Reach-RecordHigh-Annual-Revenues-Through-2022/",
title="MCUs Sales to Reach Record-High Annual Revenues Through 2022",
author={IC Insights},
year={2018},
month={11},
}

@article{MicrosoftCNTK,
  title={An introduction to computational networks and the computational network toolkit},
  author={Yu, Dong and Eversole, Adam and Seltzer, Mike and Yao, Kaisheng and Huang, Zhiheng and Guenter, Brian and Kuchaiev, Oleksii and Zhang, Yu and Seide, Frank and Wang, Huaming and others},
  journal={Microsoft Technical Report MSR-TR-2014--112},
  year={2014}
}


@misc{Forurensningsloven,
    title="Forskrift om begrensning av forurensning, del 2. Støy",
    url="https://lovdata.no/dokument/SF/forskrift/2004-06-01-931/KAPITTEL_2#KAPITTEL_2",
    year={2004},
    keywords="legislation",
}

@Article{AudioCodingSensorGrid,
AUTHOR = {Gontier, Félix and Lagrange, Mathieu and Aumond, Pierre and Can, Arnaud and Lavandier, Catherine},
TITLE = {An Efficient Audio Coding Scheme for Quantitative and Qualitative Large Scale Acoustic Monitoring Using the Sensor Grid Approach},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2758},
URL = {http://www.mdpi.com/1424-8220/17/12/2758},
ISSN = {1424-8220},
DOI = {10.3390/s17122758},
}

@misc{IECSoundLevelMeters,
title="IEC 61672-1 Sound Level Meters, part 1: Specifications",
year={2013},
url="https://standards.globalspec.com/std/1634276/iec-61672-1",
}
@misc{ANSISoundLevelMeters,
title={ANSI S1.4-2014, Part 1: Specifications for Sound Level Meters},
year={2014},
author={Acoustical Society of America},
url="https://webstore.ansi.org/Standards/ASA/ANSIASAS12014PartIEC616722013"
}

@misc{IECPersonalSoundExposureMeters,
title="IEC 61252 Personal Sound Exposure Meters",
year={2017},
url="https://standards.globalspec.com/std/10153028/IEC%2061252",
}
@misc{IECOctaveBands,
title="IEC 61260-1:2014",
year={2014},
url="https://webstore.iec.ch/publication/5063",
}

@misc{ANSIOctaveBands,
title={ANSI S1.11-2004: Octave-Band and Fractional-Octave-Band Analog and Digital Filters},
year={2004},
url={https://webstore.ansi.org/standards/asa/ansiasas1112004r2009}
}

@Article{AudioCodingSensorGrid,
AUTHOR = {Gontier, Félix and Lagrange, Mathieu and Aumond, Pierre and Can, Arnaud and Lavandier, Catherine},
TITLE = {An Efficient Audio Coding Scheme for Quantitative and Qualitative Large Scale Acoustic Monitoring Using the Sensor Grid Approach},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2758},
URL = {http://www.mdpi.com/1424-8220/17/12/2758},
ISSN = {1424-8220},
DOI = {10.3390/s17122758},
}

@article{IncrementalNetworkQuantization,
  author    = {Aojun Zhou and
               Anbang Yao and
               Yiwen Guo and
               Lin Xu and
               Yurong Chen},
  title     = {Incremental Network Quantization: Towards Lossless CNNs with Low-Precision
               Weights},
  journal   = {CoRR},
  volume    = {abs/1702.03044},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.03044},
  archivePrefix = {arXiv},
  eprint    = {1702.03044},
  timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhouYGXC17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{leng2018extremely,
  title={Extremely low bit neural network: Squeeze the last bit out with ADMM},
  author={Leng, Cong and Dou, Zesheng and Li, Hao and Zhu, Shenghuo and Jin, Rong},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{miyashita2016convolutional,
  title={Convolutional neural networks using logarithmic data representation},
  author={Miyashita, Daisuke and Lee, Edward H and Murmann, Boris},
  journal={arXiv preprint arXiv:1603.01025},
  year={2016}
}

@article{cintra2018low,
  title={Low-complexity approximate convolutional neural networks},
  author={Cintra, Renato J and Duffner, Stefan and Garcia, Christophe and Leite, Andr{\'e}},
  journal={IEEE transactions on neural networks and learning systems},
  number={99},
  pages={1--12},
  year={2018},
  publisher={IEEE}
}

@inproceedings{andri2016yodann,
  title={YodaNN: An ultra-low power convolutional neural network accelerator based on binary weights},
  author={Andri, Renzo and Cavigelli, Lukas and Rossi, Davide and Benini, Luca},
  booktitle={2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={236--241},
  year={2016},
  organization={IEEE}
}

@article{cintra2018low,
  title={Low-complexity approximate convolutional neural networks},
  author={Cintra, Renato J and Duffner, Stefan and Garcia, Christophe and Leite, Andr{\'e}},
  journal={IEEE transactions on neural networks and learning systems},
  number={99},
  pages={1--12},
  year={2018},
  publisher={IEEE}
}

@inproceedings{bagherinezhad2017lcnn,
  title={Lcnn: Lookup-based convolutional neural network},
  author={Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7120--7129},
  year={2017}
}

@inproceedings{akbacs2015multiplication,
  title={Multiplication-free neural networks},
  author={Akba{\c{s}}, Cem Emre and Bozkurt, Alican and {\c{C}}etin, A Enis and {\c{C}}etin-Atalay, Rengul and {\"U}ner, Ay{\c{s}}eg{\"u}l},
  booktitle={2015 23nd Signal Processing and Communications Applications Conference (SIU)},
  pages={2416--2418},
  year={2015},
  organization={IEEE}
}

@article{BatchNormalization,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{smith1997scientist,
  title={The scientist and engineer's guide to digital signal processing},
  author={Smith, Steven W and others},
  year={1997},
  publisher={California Technical Pub. San Diego}
}


@article{Mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@article{Cutout,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1708.04552},
  year={2017}
}

@InProceedings{Mixup-ASC,
author="Xu, Kele
and Feng, Dawei
and Mi, Haibo
and Zhu, Boqing
and Wang, Dezhi
and Zhang, Lilun
and Cai, Hengxing
and Liu, Shuwen",
editor="Hong, Richang
and Cheng, Wen-Huang
and Yamasaki, Toshihiko
and Wang, Meng
and Ngo, Chong-Wah",
title="Mixup-Based Acoustic Scene Classification Using Multi-channel Convolutional Neural Network",
booktitle="Advances in Multimedia Information Processing -- PCM 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="14--23",
isbn="978-3-030-00764-5"
}


@inproceedings{Xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@article{NoiseStressConcept,
IDS = {NoiseSeverityPyramid},
author = {Babisch, Wolfgang.},
title =  {The noise/stress concept, risk assessment and research needs},
journal  ={Noise and Health},
volume ={4},
number ={16},
pages  = {1-11},
year  = {2002},
URL ={http://www.noiseandhealth.org/article.asp?issn=1463-1741;year=2002;volume=4;issue=16;spage=1;epage=11;aulast=Babisch;t=6},
eprint ={http://www.noiseandhealth.org/article.asp?issn=1463-1741;year=2002;volume=4;issue=16;spage=1;epage=11;aulast=Babisch;t=6}
}

@book{ComputationalAnalysisSound,
author = {Virtanen, Tuomas and Plumbley, Mark and Ellis, Dan},
year = {2017},
month = {09},
pages = {1-422},
title = {Computational Analysis of Sound Scenes and Events},
journal = {Computational Analysis of Sound Scenes and Events},
doi = {10.1007/978-3-319-63450-0},
ISBN = "978-3-319-63450-0",
}

@article{MultipleInstanceLearning2008,
  title={Multiple instance learning: algorithms and applications},
  author={Babenko, Boris},
  journal={View Article PubMed/NCBI Google Scholar},
  pages={1--19},
  year={2008}
}

@inproceedings{ESC-50,
  title = {{ESC}: {Dataset} for {Environmental Sound Classification}},
  author = {Piczak, Karol J.},
  booktitle = {Proceedings of the 23rd {Annual ACM Conference} on {Multimedia}},
  date = {2015-10-13},
  url = {http://dl.acm.org/citation.cfm?doid=2733373.2806390},
  doi = {10.1145/2733373.2806390},
  location = {{Brisbane, Australia}},
  isbn = {978-1-4503-3459-4},
  publisher = {{ACM Press}},
  pages = {1015--1018}
}

@online{ESC-50-Github,
    title={karoldvl/ESC-50 on Github},
    author={Piczak, Karol J},
    url="https://github.com/karoldvl/ESC-50",
}

@inproceedings{AudioSet,
title	= {Audio Set: An ontology and human-labeled dataset for audio events},
author	= {Jort F. Gemmeke and Daniel P. W. Ellis and Dylan Freedman and Aren Jansen and Wade Lawrence and R. Channing Moore and Manoj Plakal and Marvin Ritter},
year	= {2017},
booktitle	= {Proc. IEEE ICASSP 2017},
address	= {New Orleans, LA}
}


@inproceedings{PiczakCNN,
  title={Environmental sound classification with convolutional neural networks},
  author={Piczak, Karol J},
  booktitle={2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@article{SB-CNN,
  author    = {Justin Salamon and
               Juan Pablo Bello},
  title     = {Deep Convolutional Neural Networks and Data Augmentation for Environmental
               Sound Classification},
  journal   = {CoRR},
  volume    = {abs/1608.04363},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.04363},
  archivePrefix = {arXiv},
  eprint    = {1608.04363},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SalamonB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{D-CNN,
author = {Zhang, Xiaohu and Zou, Yuexian and Shi, Wei},
year = {2017},
month = {08},
pages = {1-5},
title = {Dilated convolution neural network with LeakyReLU for environmental sound classification},
doi = {10.1109/ICDSP.2017.8096153}
}

@inproceedings{EnvNet,
author = {Tokozume, Yuji and Harada, Tatsuya},
year = {2017},
month = {03},
pages = {2721-2725},
title = {Learning environmental sounds with end-to-end convolutional neural network},
doi = {10.1109/ICASSP.2017.7952651}
}

@article{EnvNet2,
  title={Learning from between-class examples for deep sound recognition},
  author={Tokozume, Yuji and Ushiku, Yoshitaka and Harada, Tatsuya},
  journal={arXiv preprint arXiv:1711.10282},
  year={2017}
}

@inproceedings{ESC-mixup,
  title={Deep convolutional neural network with mixup for environmental sound classification},
  author={Zhang, Zhichao and Xu, Shugong and Cao, Shan and Zhang, Shunqing},
  booktitle={Chinese Conference on Pattern Recognition and Computer Vision (PRCV)},
  pages={356--367},
  year={2018},
  organization={Springer}
}

@inproceedings{LD-CNN,
  title={LD-CNN: A Lightweight Dilated Convolutional Neural Network for Environmental Sound Classification},
  author={Zhang, Xiaohu and Zou, Yuexian and Wang, Wenwu},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},
  pages={373--378},
  year={2018},
  organization={IEEE}
}

@article{AclNet,
  title={AclNet: efficient end-to-end audio classification CNN},
  author={Huang, Jonathan J and Leanos, Juan Jose Alvarado},
  journal={arXiv preprint arXiv:1811.06669},
  year={2018}
}


@article{eGRU,
  title={An Optimized Recurrent Unit for Ultra-Low-Power Keyword Spotting},
  author={Amoh, Justice and Odame, Kofi},
  journal={arXiv preprint arXiv:1902.05026},
  year={2019}
}


@INPROCEEDINGS{VeryDeepESC,
author={W. {Dai} and C. {Dai} and S. {Qu} and J. {Li} and S. {Das}},
booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Very deep convolutional neural networks for raw waveforms},
year={2017},
volume={},
number={},
pages={421-425},
doi={10.1109/ICASSP.2017.7952190},
ISSN={2379-190X},
month={March},
}

@InProceedings{WSNet,
  title = 	 {WSNet: Compact and Efficient Networks Through Weight Sampling},
  author = 	 {Jin, Xiaojie and Yang, Yingzhen and Xu, Ning and Yang, Jianchao and Jojic, Nebojsa and Feng, Jiashi and Yan, Shuicheng},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2352--2361},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/jin18d/jin18d.pdf},
  url = 	 {http://proceedings.mlr.press/v80/jin18d.html}
}


@article{SqueezeNet,
    Author = {Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
    Title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$0.5MB model size},
    Journal = {arXiv:1602.07360},
    Year = {2016}
}

@article{SqueezeNext,
  author    = {Amir Gholami and
               Kiseok Kwon and
               Bichen Wu and
               Zizheng Tai and
               Xiangyu Yue and
               Peter H. Jin and
               Sicheng Zhao and
               Kurt Keutzer},
  title     = {SqueezeNext: Hardware-Aware Neural Network Design},
  journal   = {CoRR},
  volume    = {abs/1803.10615},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.10615},
  archivePrefix = {arXiv},
  eprint    = {1803.10615},
  timestamp = {Mon, 13 Aug 2018 16:46:45 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-10615},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Effnet,
  title={Effnet: An efficient structure for convolutional neural networks},
  author={Freeman, Ido and Roese-Koerner, Lutz and Kummert, Anton},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)},
  pages={6--10},
  year={2018},
  organization={IEEE}
}


@article{Ristretto,
  title={Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in Convolutional Neural Networks},
  author={Gysel, Philipp and Pimentel, Jon and Motamedi, Mohammad and Ghiasi, Soheil},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2018},
  publisher={IEEE},
  doi={10.1109/TNNLS.2018.2808319}
}

@online{TensorFlowGroupConvolutionPR,
    title="Tensorflow Github #25818: Add support for cudnn's group convolution",
    url={https://github.com/tensorflow/tensorflow/pull/25818}
}

@article{Mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{Mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018}
}


@inproceedings{Shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{AlexNet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}


@online{ConvolutionsIllustrated,
    author={Yusuke Uchida},
    title="Why MobileNet and Its Variants (e.g. ShuffleNet) Are Fast",
    url="https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d",
}

@inproceedings{GoogLeNet,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{ImageNet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@inproceedings{ReLu,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

@article{ELU,
  title={Fast and accurate deep network learning by exponential linear units (ELUs)},
  author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:1511.07289},
  year={2015}
}

@inproceedings{LeakyReLu,
  title={Rectifier nonlinearities improve neural network acoustic models},
  author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
  booktitle={Proc. icml},
  volume={30},
  number={1},
  pages={3},
  year={2013}
}

@inproceedings{PReLu,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@article{VGGNet,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{BackpropagationNeuralNetworks,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

@online{KendryteK210Datasheet,
    title="K210 datasheet [English]",
    author="Kendryte",
    url="https://s3.cn-north-1.amazonaws.com.cn/dl.kendryte.com/documents/kendryte_datasheet_20181011163248_en.pdf"
}

@online{GAP8vsARM,
    title="GAP8 performance versus ARM M7 on Embedded CNNs",
    author="Greenwaves Technologies",
    url="https://greenwaves-technologies.com/gap8-versus-arm-m7-embedded-cnns",
}

@online{ST-DCNN-accelerator,
    title="Demo AI slides @ STMicroelectronics NV 2018 Capital Markets Day",
    year={2018},
    month={05},
    day={15},
    author="ST Microelectronics",
    url="http://investors.st.com/events/event-details/stmicroelectronics-nv-2018-capital-markets-day",
}
@online{ARMHeliumAnnouncement,
    title="Next-generation Armv8.1-M architecture: Delivering enhanced machine learning and signal processing for the smallest embedded devices",
    year={2019},
    month={02},
    day={14},
    url="https://www.arm.com/company/news/2019/02/next-generation-armv8-1-m-architecture",
}

