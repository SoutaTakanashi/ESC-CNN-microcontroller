{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from lime import lime_image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import input_data\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ff 32 98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def setup(sample_rate=16000, clip_duration_ms=1000.0,\n",
    "            window_size_ms=30.0, window_stride_ms=10.0,\n",
    "            feature_bin_count=40, preprocess='logmel', n_classes=12,\n",
    "            silence = 10.0, unknown = 10.0,\n",
    "            testing = 10.0, validation = 10.0):\n",
    "\n",
    "    m = models.prepare_model_settings(n_classes, sample_rate,\n",
    "                                      clip_duration_ms, window_size_ms, window_stride_ms,\n",
    "                                      feature_bin_count, preprocess)\n",
    "    \n",
    "    wanted_words = 'yes,no,up,down,left,right,on,off,stop,go'.split(',')\n",
    "    p = input_data.AudioProcessor(None, '../../data/speech_dataset/',\n",
    "                                silence, unknown, wanted_words,\n",
    "                                validation, testing, m, None)\n",
    "    return m, p\n",
    "\n",
    "model_settings, audio_processor = setup(feature_bin_count=32)\n",
    "\n",
    "\n",
    "def wav_to_features(input_wav):\n",
    "    results = audio_processor.get_features_for_wav(input_wav, model_settings, session)\n",
    "    features = results[0]\n",
    "    return features\n",
    "\n",
    "#f = wav_to_features('../../data/speech_dataset/nine/122c5aa7_nohash_0.wav')\n",
    "#f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv out 25 1 186\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "first_weights:0 (float32_ref 98x8x1x186) [145824, bytes: 583296]\n",
      "first_bias:0 (float32_ref 186) [186, bytes: 744]\n",
      "first_fc_weights:0 (float32_ref 4650x128) [595200, bytes: 2380800]\n",
      "first_fc_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "second_fc_weights:0 (float32_ref 128x128) [16384, bytes: 65536]\n",
      "second_fc_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "final_fc_weights:0 (float32_ref 128x12) [1536, bytes: 6144]\n",
      "final_fc_bias:0 (float32_ref 12) [12, bytes: 48]\n",
      "Total size of variables: 759398\n",
      "Total bytes of variables: 3037592\n",
      "INFO:tensorflow:Restoring parameters from ../../data/speech-logmel32/low_latency_conv.ckpt-26000\n",
      "INFO:tensorflow:Restoring parameters from ../../data/speech-logmel32/low_latency_conv.ckpt-26000\n",
      "s (98, 32) (98, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "image_size = (98, model_settings['fingerprint_width'], 1)\n",
    "f_size = (None, 98, model_settings['fingerprint_width'], 1)\n",
    "\n",
    "processed_images = tf.placeholder(tf.float32, shape=f_size)\n",
    "model = models.create_model(processed_images, model_settings,\n",
    "                            model_architecture='low_latency_conv', is_training=False)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for f in path_list:\n",
    "        image = wav_to_features(f).squeeze()\n",
    "        s = (image.shape[0], image.shape[1], 3)\n",
    "        fake_rgb = np.ndarray(shape=s, dtype=image.dtype)\n",
    "        print('s', image.shape, fake_rgb.shape)\n",
    "        fake_rgb[:,:, 0] = image\n",
    "        fake_rgb[:,:, 1] = image\n",
    "        fake_rgb[:,:, 2] = image\n",
    "        i = tf.convert_to_tensor(fake_rgb) \n",
    "        out.append(i)\n",
    "    return session.run([out])[0]\n",
    "\n",
    "#tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "checkpoint = '../../data/speech-logmel32/low_latency_conv.ckpt-26000'\n",
    "\n",
    "models.load_variables_from_checkpoint(session, checkpoint)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "saver.restore(session, checkpoint)\n",
    "\n",
    "probabilities = model\n",
    "def predict_fn(images):\n",
    "    images = [ np.expand_dims(img[:,:,0], axis=-1) for img in images ]\n",
    "    return session.run(probabilities, feed_dict={processed_images: images})\n",
    "\n",
    "\n",
    "p = predict_fn(transform_img_fn(['../../data/speech_dataset/left/122c5aa7_nohash_0.wav']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s (98, 32) (98, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "images = transform_img_fn([\n",
    "    '../../data/speech_dataset/down/122c5aa7_nohash_0.wav'\n",
    "])\n",
    "p = predict_fn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'down'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_processor.words_list[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation time:  0.5976510047912598\n"
     ]
    }
   ],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "start_time = time.time()\n",
    "# Hide color is the color for a superpixel turned OFF.\n",
    "# Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels\n",
    "image = images[0]\n",
    "explanation = explainer.explain_instance(image, predict_fn, top_labels=5, hide_color=None, num_samples=1000)\n",
    "print('explanation time: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe1c8f554e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "temp, mask = explanation.get_image_and_mask(1, positive_only=False, num_features=5, hide_rest=False)\n",
    "fig = plt.figure(figsize=(4,12))\n",
    "fig.add_subplot(1, 1, 1)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask), aspect=1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
